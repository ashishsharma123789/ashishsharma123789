{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1040055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "Product_name=[]\n",
    "Prices=[]\n",
    "Description=[]\n",
    "Reviews=[]\n",
    "\n",
    "for i in range(2,12)\n",
    "    url=\"https://www.flipkart.com/search?q=mobile+under+50000&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(1)\n",
    "\n",
    "\n",
    "    r=requests.get(url)\n",
    "    # print(r)\n",
    "\n",
    "    soup=BeautifulSoup(r.text, \"lxml\")\n",
    "    box=soup.find(\"div\", class_=\"DOjaWF YJG4Cf\")\n",
    "    \n",
    "    names=box.find_all(\"div\", class_=\"KzDlHZ\")  \n",
    "\n",
    "    for i in names:\n",
    "        name=i.text\n",
    "        Product_name.append(name)\n",
    "    #print(Product_name)\n",
    "    prices=box.find_all(\"div\", class_=\"Nx9bqj _4b5DiR\")\n",
    "    for i in prices:\n",
    "        name=i.text\n",
    "        Prices.append(name)\n",
    "     #print(Prices)\n",
    "\n",
    "    desc=box.find_all(\"ul\",class_=\"G4BRas\")\n",
    "\n",
    "    for i in desc:\n",
    "        name=i.text\n",
    "        Description.append(name)\n",
    "    #print(Description)\n",
    "\n",
    "    reviews=box.find_all(\"div\", class_=\"XQDdHH\")\n",
    "\n",
    "    for i in reviews:\n",
    "        name=i.text\n",
    "        Reviews.append(name)\n",
    "    \n",
    "    #print(Reviews)\n",
    "\n",
    "df=pd.DataFrame({\"Product Name\":Product_name, \"Prices\":Prices, \"Description\":Description, \"Reviews\":Reviews})\n",
    "#print(df)\n",
    "df.to_csv(\"C:/Users/PC\\Documents/Cognifyz Python Internship/Level 3/flipkart_mobile_under_50000.csv\")\n",
    "\n",
    "\n",
    "                   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(soup)\n",
    "    #while True: \n",
    "    #np=soup.find(\"a\", class_=\"_9QVEpD\").get(\"href\")\n",
    "    #cnp=\"https://www.flipkart.com\"+np\n",
    "    #print(cnp)\n",
    "\n",
    "#url=cnp\n",
    "#r=requests.get(url)\n",
    "#soup=BeautifulSoup(r.text, \"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c27726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
